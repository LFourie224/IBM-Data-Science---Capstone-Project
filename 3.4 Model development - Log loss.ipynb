{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37732bitmyenvcondacdd7653a66d44e76b9f4e68fbb6ca43c",
   "display_name": "Python 3.7.7 32-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and assess the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccidentData_LogLoss = pd.read_csv('E:\\Training Development\\Coursera\\IBM Data Science\\Course 9 - Capstone Project\\Capstone Project Data\\AccidentData_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   OBJECTID  SEVERITYCODE  JUNCTIONTYPE  WEATHER  ROADCOND  LIGHTCOND  \\\n0         1             2             2        1         9          6   \n1         2             1             3        2         9          3   \n2         3             1             3        1         1          6   \n3         4             1             3        3         1          6   \n4         5             2             2        2         9          6   \n\n   Day of week  Month of Year  \n0            2              3  \n1            2             12  \n2            3             11  \n3            4              3  \n4            2              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>SEVERITYCODE</th>\n      <th>JUNCTIONTYPE</th>\n      <th>WEATHER</th>\n      <th>ROADCOND</th>\n      <th>LIGHTCOND</th>\n      <th>Day of week</th>\n      <th>Month of Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n      <td>6</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>9</td>\n      <td>3</td>\n      <td>2</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9</td>\n      <td>6</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "AccidentData_LogLoss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "189337"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(AccidentData_LogLoss.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['OBJECTID', 'SEVERITYCODE', 'JUNCTIONTYPE', 'WEATHER', 'ROADCOND',\n       'LIGHTCOND', 'Day of week', 'Month of Year'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "AccidentData_LogLoss.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dataset to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 2,  1,  9,  6,  2,  3],\n       [ 3,  2,  9,  3,  2, 12],\n       [ 3,  1,  1,  6,  3, 11],\n       [ 3,  3,  1,  6,  4,  3],\n       [ 2,  2,  9,  6,  2,  1]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X = np.asarray(AccidentData_LogLoss[['JUNCTIONTYPE', 'WEATHER', 'ROADCOND', 'LIGHTCOND', 'Day of week', 'Month of Year']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 1, 1, 1, 2], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "y = np.asarray(AccidentData_LogLoss['SEVERITYCODE'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.97301587, -0.90075769,  1.4789272 ,  0.35007251, -0.49066799,\n        -1.04183148],\n       [ 0.31901365, -0.49594889,  1.4789272 , -1.40094051, -0.49066799,\n         1.58661409],\n       [ 0.31901365, -0.90075769, -0.71204349,  0.35007251,  0.02941915,\n         1.29456458],\n       [ 0.31901365, -0.09114008, -0.71204349,  0.35007251,  0.54950629,\n        -1.04183148],\n       [-0.97301587, -0.49594889,  1.4789272 ,  0.35007251, -0.49066799,\n        -1.62593049]])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train set: (151469, 6) (151469,)\nTest set: (37868, 6) (37868,)\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(C=0.01, solver='liblinear')"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict_proba returns estimates for all classes, ordered by the label of classes. So, the first column is the probability of class 1, P(Y=1|X), and second column is probability of class 0, P(Y=0|X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.72794576, 0.27205424],\n       [0.91862133, 0.08137867],\n       [0.73439319, 0.26560681],\n       ...,\n       [0.703059  , 0.296941  ],\n       [0.74152503, 0.25847497],\n       [0.59295419, 0.40704581]])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train set Accuracy:  0.6957859363962263\nTest set Accuracy:  0.6942801309813035\n"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, LR.predict(X_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But, data is not balanced, therefore use the following:\n",
    "# - F1 score\n",
    "# - Jaccard index\n",
    "# - Precision / Recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5779906998616631"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, yhat, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6929992044550517"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average precision-recall score: 0.70\n"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, yhat)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5832384075902182"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, yhat_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}